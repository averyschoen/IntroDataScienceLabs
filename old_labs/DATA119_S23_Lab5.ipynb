{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6880c48c-16aa-439b-a4be-b327f6c8f2d5",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"DATA 119 S23 Lab 5 Solutions\"\n",
    "name: \"Amy Nussbaum\"\n",
    "format: pdf\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8371df1e-7ec6-4da4-ae3e-be72208e8211",
   "metadata": {},
   "source": [
    "# Lab 5 Goals\n",
    "\n",
    "The goals of this lab are:\n",
    "\n",
    "* To implement leave-one-out and $K$-fold cross validation in a regression setting. \n",
    "* To select a tuning parameter and apply ridge regression to the datasets used for regression. \n",
    "\n",
    "For this lab, it may be helpful to install and load the following modules:\n",
    " \n",
    "* `numpy`\n",
    "* `pandas`\n",
    "* `plotnine`\n",
    "* `random`\n",
    "* `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc16586-f9b8-45ec-8564-14b216d1923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotnine as p9\n",
    "import random\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d689bf-8e7b-47a9-b554-74be4f57d564",
   "metadata": {},
   "source": [
    "We will be using the AirBnB prices dataset from Homeworks 1 and 2. Refresh yourself on the variables it includes by reading the [Kaggle documentation](https://www.kaggle.com/datasets/thedevastator/airbnb-prices-in-european-cities) as well as the [documentation from the original source, Zenodo.](https://zenodo.org/record/4446043#.ZCTMTezMK3J) Now that you know how it should be cleaned, you can download the full dataset from Canvas and upload it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6988c2d6-31e0-4916-810c-f4c48a64d62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AirBnB_prices = pd.read_csv(\"AirBnB_prices.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09b924-1c4e-46b1-b6a4-8b2a5e6d0167",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "1. We've looked at this dataset in class, but you haven't necessarily explored it by yourself. Take some time to look at summary statistics and distributions of each of the variables. Now might also be a good time to identify categorical variables and convert them to indicators--remember that price is named `realSum` and `room_type` already has been converted into indicators for `room_shared` and `room_private`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b9817-c1a5-4c42-9f3d-204435787594",
   "metadata": {},
   "outputs": [],
   "source": [
    "AirBnB_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0de8e3-bc9a-447a-adda-01cbbea70134",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "2. We have been using `statsmodels` for the extra information packaged into the `.summary()` output, but we should also familiarize ourself with the `sklearn` syntax. First, save the predictors as `X` (don't forget you don't need the normalized and unnormalized predictors, and you only need $k-1$ of each of the indicators), and save the log of `realSum` as `Y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb0d3a-40c6-4f7c-aa3d-bdb4b3a897d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = AirBnB_prices[['room_shared', 'room_private', 'person_capacity', 'host_is_superhost', \n",
    "                   'multi', 'biz', 'cleanliness_rating', 'guest_satisfaction_overall', \n",
    "                   'bedrooms', 'dist', 'metro_dist', 'attr_index', 'rest_index', 'lng', \n",
    "                   'lat', 'city_athens', 'city_barcelona', 'city_berlin', 'city_budapest',\n",
    "                   'city_lisbon', 'city_london', 'city_paris', 'city_rome', 'city_vienna',\n",
    "                   'dayType_weekends']]\n",
    "\n",
    "Y = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6fb4fb-54a3-4dde-94f6-63b4cf87b838",
   "metadata": {},
   "source": [
    "3. Now, review the documentation for [`sklearn`'s `LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). Fit the model and print out the coefficients--make sure you know how to add the intercept, since we did not add a constant! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe3b0b-56d9-436d-a751-0ccd1dbca979",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = sklearn.linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326b6615-99cf-468a-a5e7-41ef514fe66f",
   "metadata": {},
   "source": [
    "4. Now, see if you can use `.predict()` to get the predicted values (save them as `preds0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097be347-ca7b-4815-b6ed-0ae49c5c2628",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds0 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15e510-7a8c-413d-a211-0a805c6a5222",
   "metadata": {},
   "source": [
    "5. Remember that for cross validation we want to get the errors for each observation and then \"aggregate\" them somehow. \"Aggregate\" in this context just means combine in a meaningful way--for cross validation with a numeric response, this often just means taking the sum of the squared errors (a.k.a., the loss function for ordinary least squares). We aren't cross validating just yet, but practice calculating this quantity with your existing model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c4f27-a3b0-4416-bcb3-5e0d587a0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "resids0 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e626f-529e-4922-93f0-3d17d4117f4a",
   "metadata": {},
   "source": [
    "### Leave-One-Out Cross Validation\n",
    "\n",
    "Now, let's consider leave-one-out cross validation. In this context, we will leave out one row of the dataframe at a time, use the remaining rows to fit a linear regression model, and use that model to predict the response for the left-out row. We'll save that value, put the row back in, and repeat the process for the rest of the dataset. \n",
    "\n",
    "6. First, use the `drop()` and `.loc()` methods from `pandas` to split the dataset into two smaller datasets of the predictors--a dataframe called `Xrows_out` and a dataframe called `Xrows_in`. Leave the first row out and examine the datasets to make sure they have 1 row and $n-1$ rows, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bbb812-8770-40a3-92ee-dfeba348ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xrows_out = \n",
    "Xrows_in = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fc75db-ded4-43a9-bfa8-ac40379859d7",
   "metadata": {},
   "source": [
    "7. Note that `Xrows_out` is no longer a dataframe. This will cause issues later, so take a minute to familiarize yourself with the code to turn it back into a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac06b3-4cc2-42b0-89ee-c147afd101e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xrows_out = Xrows_out.to_frame().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b451233e-8825-4a74-979e-325f4743b08e",
   "metadata": {},
   "source": [
    "8. Repeat Step 6. for the response `Y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f810592-5611-48c0-b325-bbccba8e6d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edbe06f6-f10b-4469-adcf-ddb90ea3b11c",
   "metadata": {},
   "source": [
    "9. Using your code from 3., fit the model with the bigger of the two datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d6d1a-c87c-409a-b834-e78efbd83ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = sklearn.linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da780a4c-c9dc-4203-ae7c-ee4f737a5d0a",
   "metadata": {},
   "source": [
    "10. Now, predict the response for the left out row (use code from Step 4). I saved mine as `pred1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d5c42-d365-4c64-b57d-72f72a3ca590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5171d30-3943-4037-b05f-55898986cb85",
   "metadata": {},
   "source": [
    "11. Now, find the residual for the left out observation and square it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89675f8-d9c9-423e-b6dd-448aa0036091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7656c9af-d458-4f57-8fad-c845259461b9",
   "metadata": {},
   "source": [
    "12. You have the general steps down! Now, combine Steps 6 - 11 into a loop. Make sure to create an empty object to save the squared residuals in and save them in each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e92ad-fc9e-47ed-8ecb-6e6354c47fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resids_LOO = []\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "  Xrows_out =\n",
    "  Xrows_in = \n",
    "\n",
    "  Yrows_out =\n",
    "  Yrows_in =\n",
    "\n",
    "  modelLOO = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f528bc-f073-490c-be15-944fbb0ca92e",
   "metadata": {},
   "source": [
    "13. Take the sum of the squared residuals. Now, you can compare this value to similar cross-validated scores from other models! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83538c-a721-49c9-af82-f3f60b59a480",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de314a8c-7cd7-481c-b4c5-3c56cd6a2b54",
   "metadata": {},
   "source": [
    "### $K$-Fold Cross Validation\n",
    "\n",
    "You've probably noticed that while it takes a neglible amount of time to fit one linear regression model, it takes quite a bit longer to fit 50,000+ of them. This is a perfect example of why you might prefer $K$-Fold Cross Validation, where $K$ is usually 5 or 10. With the exception of a few minor details, the code is extremely similar--let's proceed with 5-Fold CV. \n",
    "\n",
    "14. First, run the following lines of code. Can you figure out what this does?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4553022-4ce2-4f66-8888-694cd759a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = AirBnB_prices.shape[0]\n",
    "\n",
    "Xrows_out = X.loc[range(0, round(n/5) - 1)]\n",
    "Xrows_in = X.drop(range(0, round(n/5) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5c4edb-c342-43b0-9ffa-bb008e74d7f3",
   "metadata": {},
   "source": [
    "15. Now, run these new lines of code. What's wrong with choosing the first fold in this way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782f555-176e-407a-918a-7c1b368e2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xrows_out.head()\n",
    "Xrows_in.head()\n",
    "\n",
    "Xrows_out.tail()\n",
    "Xrows_in.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2709cf83-f288-412b-9d40-86b91fd56400",
   "metadata": {},
   "source": [
    "16. To address this issue, I like to \"scramble\" the rows, a.k.a., put them in random order. We can do it by selecting a sample of size $n$ from the range of 0 to $n-1$ (to account for zero-indexing). Run the following line of code--I've saved it as `ind` for index. Review each line to make sure you understand each step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b0b44-4802-40bf-8f38-d167ba0b4a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(108)\n",
    "\n",
    "ind = random.sample(range(0, n), k = n)\n",
    "\n",
    "ind1 = ind[0:(round(n/5))]\n",
    "\n",
    "Xrows_out = X.loc[ind1]\n",
    "Xrows_in = X.drop(ind1)\n",
    "\n",
    "Yrows_out = Y.loc[ind1]\n",
    "Yrows_in = Y.drop(ind1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d211c3-1af5-461e-aa00-86a3640af3ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27ded7cc-96d7-4c92-ba5d-3376d2222c9b",
   "metadata": {},
   "source": [
    "17. We can generalize this if we're a bit clever about the indexing. Walk through the lines of loop that will perform 5-Fold CV--can you see what is going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e61ecbe-d839-4410-8f9b-11b53e2ac9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resids_KFold = []\n",
    "\n",
    "for k in range(0, 5):\n",
    "  indk = range(round(k*n/5), round((k+1)*n/5)-1)\n",
    "\n",
    "  Xrows_out = X.loc[indk]\n",
    "  Xrows_in = X.drop(indk)\n",
    "\n",
    "  Yrows_out = Y.loc[indk]\n",
    "  Yrows_in = Y.drop(indk)\n",
    "  \n",
    "  modelKFold = sklearn.linear_model.LinearRegression(fit_intercept = True).fit(Xrows_in, Yrows_in)\n",
    "\n",
    "  predKFold = modelKFold.predict(Xrows_out)\n",
    "\n",
    "  residKFold = Yrows_out - predKFold\n",
    "  resids_KFold.append(residKFold**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682c8041-a441-4e94-a0e7-8c2d67cff66b",
   "metadata": {},
   "source": [
    "18. You can once again use the sum to aggregate the squared residuals and compare these to other metrics calculated using 5-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda5d83-0141-4748-a76b-9eecccb24e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3855fb1-af7f-4026-9e4e-fa3a636e592f",
   "metadata": {},
   "source": [
    "It is good that you've programmed cross-validation by hand this one time. Out of all the things we've covered in class, cross validation is the one thing that I regularly write my own code for, rather than using a pre-packaged routine. That being said, for DATA119, I think it is okay to use a package that you trust. Let's look at the [`cross_val_score()` function in `sklearn`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score). 22. We have learned previously that to create plots with `plotnine` we need to create a dataframe. Create a dataframe with columns for `threshold` and each of the coefficients in the model--you may want to rename the columns for convenience later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f995fa8-ee5a-462e-9c9d-50b15fef3adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674e4770-c6a3-4335-8dfe-df5af8a90003",
   "metadata": {},
   "source": [
    "`cross_val_score()` accepts the following arguments:\n",
    "\n",
    "* `estimator`: estimator object implementing `fit`, the object to use to fit the data. We usually save this as `model` or something similar.\n",
    "* `X`: The data to fit. Can be for example a list, or an array--we have been using dataframes.\n",
    "* `y`: The target variable to try to predict in the case of supervised learning. We have been calling this the response. \n",
    "* ... (other arguments not important at the moment)\n",
    "* `scoring`: A \"str\" (see model evaluation documentation) or a scorer callable object / function with signature scorer(estimator, X, y) which should return only a single value. If `None`, the estimatorâ€™s default scorer (if available) is used.\n",
    "* `cvint`: Determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
    "  + `None`, to use the default 5-fold cross validation,\n",
    "  + `int`, to specify the number of folds in a (Stratified)KFold,\n",
    "  + CV splitter\n",
    "  + An iterable that generates (train, test) splits as arrays of indices.\n",
    "  \n",
    "Hopefully you more or less know what to put in for `estimator`, `X`, and `y`. `cvint` is also more or less straightforward, I think we will be using `None` or `int` most of the time. The `scoring` method is more interesting! Look at the [documentation for `scoring`](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter). There are many different ways to score, but hopefully you recognize two things on this page--first, the methods for scoring are different for classifiers and regression models (models with numerical responses). Second, there are a few terms you should be familiar with, like `roc`, `auc`, `accuracy`, `explained_variance`, etc. \n",
    "\n",
    "The closest method to what we covered in class is `neg_mean_squared_error`, with two minor differences. First--I showed you how to calculate the sum of squared errors, which we would want to minimize. By taking the negative value, we've converted this into something we want to maximize. Second--we are now looking at the mean of the squared errors--this is the same as the sum, just divided by the number of observations (a constant).\n",
    "\n",
    "19. The following code calculates a 5-Fold cross validated score for our model. Can you adapt it to produce a 10-Fold CV score? Make sure you are using `neg_mean_squared_error`. You may want to refer to your code from Step 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b631643-fbe1-42b6-8110-287355fb4e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LinReg = sklearn.linear_model.LinearRegression(fit_intercept = True)\n",
    "cross_val_score(LinReg, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ba1f3b-7b43-4f88-834a-2fed7dc09e33",
   "metadata": {},
   "source": [
    "LinReg = sklearn.linear_model.LinearRegression(fit_intercept = True)\n",
    "cross_val_score(LinReg, X, Y, cv=10, scoring = \"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3078ab-82be-4d0b-8a02-d26573735ace",
   "metadata": {},
   "source": [
    "20. One more tiny step--`cross_val_score()` returns the scores for each fold. Can you aggregate them to produce one single metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e341712-afce-4736-81f1-dffdb762d3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82f3f232-8e8a-45cb-a46e-ae5b150e64df",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "\n",
    "21. Now let's move onto fitting ridge regression. Remember that we need to standardize the data--you can still use `StandardScaler` from `sklearn` ([the documentation is here if you need it](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)), but it's important to note that you want to \"pretend\" that your training data is all that you have and your testing data is brand new. The testing data should not be accounted for when you are scaling the data! However, it does also need to be scaled using the means and standard deviations from the training data. See the code below for an example of the data scaling used in Fold 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef127c1-53a9-4f8b-bc17-f276eee03e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xrows_out = X.loc[ind1]\n",
    "Xrows_in = X.drop(ind1)\n",
    "\n",
    "Yrows_out = Y.loc[ind1]\n",
    "Yrows_in = Y.drop(ind1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "Xrows_in_pp = pd.DataFrame(scaler.transform(), columns = [['room_shared', 'room_private', 'person_capacity', 'host_is_superhost', 'multi', 'biz', 'cleanliness_rating', 'guest_satisfaction_overall', 'bedrooms', 'dist', 'metro_dist', 'attr_index', 'rest_index', 'lng', 'lat', 'city_athens', 'city_barcelona', 'city_berlin', 'city_budapest', 'city_lisbon', 'city_london', 'city_paris', 'city_rome', 'city_vienna', 'dayType_weekends']])\n",
    "Xrows_out_pp = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc082442-6e03-4fb5-ae5c-e98db65156c0",
   "metadata": {},
   "source": [
    "22. Even though we aren't performing feature selection with ridge regression, it is still common to fit the models with all of the variables. The most straightforward way to do this is to use the `linear_model.Ridge` method from `sklearn`. Read [the documentation for `Ridge`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) and fit a model predicting the log of the AirBnB's price (ignore the threshold parameter for now). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b74b8-fe97-42ca-9037-7c3b32e0b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model\n",
    "modelRidge = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41fbddf-b195-49f0-9974-34f82404822d",
   "metadata": {},
   "source": [
    "Once you read the documentation and successfully fit the model, you should find that it is relatively simple to add different thresholds. Remember that different software programs and even different functions have different names for the threshold parameter--in fact, the following are all different names for the same concept:\n",
    "\n",
    "* Threshold parameter\n",
    "* Regularization parameter\n",
    "* Tuning parameter (presented in the book [James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. An introduction to statistical learning. Vol. 112. New York: springer, 2013.](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf))\n",
    "* $T$ (presented in the Week 4 LASSO notes on April 10)\n",
    "* $\\lambda$ (presented in the book on LASSO, [Hastie, Trevor, Robert Tibshirani, and Martin Wainwright. \"Statistical learning with sparsity.\" Monographs on statistics and applied probability 143 (2015): 143.](https://hastie.su.domains/StatLearnSparsity_files/SLS.pdf))\n",
    "* `C` (used in `sklearn.linear_model.LogisticRegression`, among others)\n",
    "* `alpha` (used in `sklearn.linear_model.Ridge()`, among others)\n",
    "\n",
    "Be careful to double, triple, quadruple check the `sklearn` documentation to figure out what you are supposed to be using! Note further that `C` is described as the inverse of regularization strength, so smaller values mean a more restrictive model (the opposite of what we have been considering). \n",
    "\n",
    "23. In the case of `.Ridge()`, we will be using `alpha` where `alpha = 0` is equivalent to least squares regression. Adapt the code from 20 to change the value of `alpha`, just to test the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4331e7-1659-41f8-94a5-3636a2594779",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.Ridge()\n",
    "modelRidge = model.fit(Xrows_in_pp, Yrows_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b751e78-aa0a-417c-9a30-e605da005dac",
   "metadata": {},
   "source": [
    "24. Now, we are ready to use cross validation to try and select the best `alpha` for our dataset. We could adapt the code we wrote in the previous section, but let's also consider a method built into `sklearn`--[sklearn.linear_model.RidgeCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV). Review the documentation for the `cv` argument--you'll see there are actually options for all three CV methods we have learned so far:\n",
    "\n",
    "* \"An iterable yielding (train, test) splits as arrays of indices\" for a single split into a training and test set (I am less familiar with this option, and would recommend one of the other two), \n",
    "* `cv = K` where `K` is an integer for $K$-Fold CV, and\n",
    "* `cv = None` for efficient leave-one-out CV (likely much faster than what we programmed on our own).\n",
    "\n",
    "Can you edit the code below to produce a tuning parameter selected with 5-Fold CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f99940-e0c2-4615-8eea-65db30187c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X_pp = pd.DataFrame(scaler.transform(X), columns = [['room_shared', 'room_private', 'person_capacity', 'host_is_superhost', 'multi', 'biz', 'cleanliness_rating', 'guest_satisfaction_overall', 'bedrooms', 'dist', 'metro_dist', 'attr_index', 'rest_index', 'lng', 'lat', 'city_athens', 'city_barcelona', 'city_berlin', 'city_budapest', 'city_lisbon', 'city_london', 'city_paris', 'city_rome', 'city_vienna', 'dayType_weekends']])\n",
    "\n",
    "clf = RidgeCV(alphas = np.arange(0.1, 100, 1)).fit(X_pp, Y)\n",
    "clf.score(X_pp, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a71a477-77f5-4a3a-aae5-acb3dcbcb016",
   "metadata": {},
   "source": [
    "25. Note that the code in 24. produces only one set of coefficients with the chosen threshold--so we know what the threshold is, but we don't have the nice plots we are used to seeing. To do that, you can adapt last week's code. Edit the chunk below so that we are performing ridge regression rather than the LASSO, and produce the plots (note that I plotted the log of the inverse of `alpha` for the nicest plots). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04978143-6a05-4ce8-be56-7a986c37ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_lasso = pd.DataFrame()\n",
    "auc_list = []\n",
    "\n",
    "for threshold in Cs:\n",
    "  model = sklearn.linear_model.LogisticRegression(penalty='l1', solver = 'liblinear', C=threshold)\n",
    "  tempmodel = model.fit(X_train_pp, Y_train)\n",
    "  coefs_lasso = pd.concat([coefs_lasso, pd.Series(tempmodel.coef_[0]).to_frame().T], ignore_index=True)\n",
    "  pred = tempmodel.predict(X_test_pp)\n",
    "  fpr, tpr, thresholds = metrics.roc_curve(Y_test, pred, pos_label=1)\n",
    "  auc_list.append(metrics.auc(fpr, tpr))\n",
    "\n",
    "arrests_lasso_plt = coefs_lasso\n",
    "arrests_lasso_plt.rename(columns={0: 'year', 1: 'age',\n",
    "                                  2: 'checks', 3: 'race_Black',\n",
    "                                  4: 'sex_Male', 5: 'employed_Yes',\n",
    "                                  6: 'citizen_Yes'}, inplace = True)\n",
    "\n",
    "arrests_lasso_plt['Threshold'] = Cs\n",
    "\n",
    "arrests_lasso_plt_melt = pd.melt(arrests_lasso_plt, id_vars = 'Threshold', \n",
    "                                 var_name = 'Variable', value_name = 'Coefficient')\n",
    "                                \n",
    "max_T = arrests_lasso_plt_melt['Threshold'].loc[arrests_lasso_plt_melt.shape[0]-1]\n",
    "\n",
    "plt_label = arrests_lasso_plt_melt[(arrests_lasso_plt_melt['Threshold'] == max_T)]\n",
    "\n",
    "(p9.ggplot(arrests_lasso_plt_melt, p9.aes(x = 'Threshold', y = 'Coefficient', \n",
    "                                          color = 'Variable')) +\n",
    "  p9.geom_line() +\n",
    "  p9.theme(legend_position = \"none\") +\n",
    "  p9.geom_label(inherit_aes = False, data = plt_label, \n",
    "                mapping = p9.aes(label = 'Variable', x = 0.2, \n",
    "                                 y = 'Coefficient', color = 'Variable')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789d6b3-d8bb-4cf4-b78b-e2f4a0e9eaa4",
   "metadata": {},
   "source": [
    "26. One nice thing to add to this plot would be a vertical line indicating where the regularization parameter actually is so we can quickly draw conclusions. We can do so using the command `p9.geom_vline()` for **V**ertical line. Remember that we can pull the parameter out using `.alpha_`--try and add this line to the plot. Once you've done so, can you find out which variables are helpful? Which has the largest coefficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943935b0-da3c-4512-b13d-15418a4ef1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(AirBnB_ridge_plt_melt, p9.aes(x = 'Threshold', y = 'Coefficient', color = 'Variable')) +\n",
    "       p9.geom_line() +\n",
    "       p9.scale_x_continuous(name = \"log(T)\", limits = [-4.61, 2.6]) + \n",
    "       p9.theme(legend_position = \"none\", figure_size = [6, 3.75]) +\n",
    "       p9.geom_label(inherit_aes = False, data = plt_label, ha = 'left',\n",
    "                     mapping = p9.aes(label = 'Variable', x = np.log(1/0.1), # \n",
    "                                      y = 'Coefficient', color = 'Variable', size = 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
