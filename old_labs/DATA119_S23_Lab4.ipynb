{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6880c48c-16aa-439b-a4be-b327f6c8f2d5",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"DATA 119 S23 Lab 4 Solutions\"\n",
    "name: \"Amy Nussbaum\"\n",
    "format: pdf\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8371df1e-7ec6-4da4-ae3e-be72208e8211",
   "metadata": {},
   "source": [
    "# Lab 4 Goals\n",
    "\n",
    "The goals of this lab are:\n",
    "\n",
    "* To continue practicing with logistic regression models. \n",
    "* To calculate model fit statistics. \n",
    "* To calculate confusion matrices. \n",
    "* To apply LASSO to datasets used for linear and logistic regression. \n",
    "\n",
    "For this lab, it may be helpful to install and load the following modules:\n",
    "    \n",
    "* `numpy`\n",
    "* `pandas`\n",
    "* `plotnine`\n",
    "* `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc16586-f9b8-45ec-8564-14b216d1923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotnine as p9\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e2f19e-3eee-4f18-8335-c39a2809772c",
   "metadata": {},
   "source": [
    "We will also use new modules, `random` and `scikit-learn`. Install and load them now. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce94f3f-c085-4f40-9d11-b323e1de0efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d689bf-8e7b-47a9-b554-74be4f57d564",
   "metadata": {},
   "source": [
    "For this lab, we will continue using the Toronto Star arrests dataset discussed in lecture. Refresh yourself on the included variables by reading the [dataset documentation](https://vincentarelbundock.github.io/Rdatasets/doc/carData/Arrests.html). Download the dataset from Canvas and load it into your workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6988c2d6-31e0-4916-810c-f4c48a64d62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrests = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09b924-1c4e-46b1-b6a4-8b2a5e6d0167",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "1. We've looked at this dataset in class, but you haven't necessarily explored it by yourself. Take some time to look at summary statistics and distributions of each of the variables. Now might also be a good time to identify categorical variables and convert them to indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b9817-c1a5-4c42-9f3d-204435787594",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0de8e3-bc9a-447a-adda-01cbbea70134",
   "metadata": {},
   "source": [
    "2. Now that you have familiarized yourself with the data, split the data into a 70\\% training set and a 30\\% training set using the `sample` function from the `random` module, and the `.drop()` and `.loc` methods. Note that when you randomly split, you will get a different dataset each time--this will lead to consistent, but different, results. If you want to have the same results every time, you can set a random seed first--use the `.seed()` method from the `random` package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb0d3a-40c6-4f7c-aa3d-bdb4b3a897d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(651)\n",
    "\n",
    "ind = random.sample(range(), round())\n",
    "\n",
    "arrests_test = .drop(ind)\n",
    "arrests_train = .loc[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6fb4fb-54a3-4dde-94f6-63b4cf87b838",
   "metadata": {},
   "source": [
    "# Model Fit Statistics\n",
    "\n",
    "3. Now, using your training set, fit a logistic regression model predicting whether an individual is released with a summons using the `statsmodel` syntax. Use any (or all) of the variables you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe3b0b-56d9-436d-a751-0ccd1dbca979",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = \n",
    "\n",
    "Y_train = \n",
    "\n",
    "model1 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326b6615-99cf-468a-a5e7-41ef514fe66f",
   "metadata": {},
   "source": [
    "4. Print out the `summary` output. Recall that some of the metrics we use to evaluate logistic regression models are $AIC$ and $BIC$. Can you find those values in the output?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097be347-ca7b-4815-b6ed-0ae49c5c2628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a15e510-7a8c-413d-a211-0a805c6a5222",
   "metadata": {},
   "source": [
    "5. Last week we saw that sometimes we don't need all of the printed output, and sometimes we would like to find specific values. First, we need to identify what is included in the model fitting process. Apply the `dir()` function to your model to see what is included. Scan the terms--are there any that you recognize?\n",
    "\n",
    "6. Hopefully you can see that $AIC$ and $BIC$ are included. Pull them out of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c4f27-a3b0-4416-bcb3-5e0d587a0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e626f-529e-4922-93f0-3d17d4117f4a",
   "metadata": {},
   "source": [
    "7. Another common method for evaluating logistic regression models is the confusion matrix. Take another look at the terms that are included in the regression model. Can you find something that looks like it might be the confusion matrix?\n",
    "\n",
    "8. Hopefully you located `pred_table`. Print it out. Can you identify which cell is the true positives? What about the false positives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bbb812-8770-40a3-92ee-dfeba348ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fc75db-ded4-43a9-bfa8-ac40379859d7",
   "metadata": {},
   "source": [
    "9. Be careful when using `pred_table`! In this method, the rows indicate the truth and the columns indicate the predictions, which is \"flipped\" (transposed, if you want the more formal mathematical term) from what I presented in class. Read the [`pred_table` documentation](https://www.statsmodels.org/dev/generated/statsmodels.discrete.discrete_model.LogitResults.pred_table.html) to confirm. Then, calculate the accuracy, true positive rate, true negative rate, positive predictive value, and negative predictive value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac06b3-4cc2-42b0-89ee-c147afd101e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b451233e-8825-4a74-979e-325f4743b08e",
   "metadata": {},
   "source": [
    "10. Remember that we might want a baseline accuracy to compare with the new accuracy. What is the baseline accuracy for this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f810592-5611-48c0-b325-bbccba8e6d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edbe06f6-f10b-4469-adcf-ddb90ea3b11c",
   "metadata": {},
   "source": [
    "11. Now recall that to avoid model fitting, we want to measure performance on the training set. Use the `.predict()` method to predict the outcome for the test set. Save the list to use for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d6d1a-c87c-409a-b834-e78efbd83ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = \n",
    "\n",
    "Y_test = \n",
    "\n",
    "preds1 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da780a4c-c9dc-4203-ae7c-ee4f737a5d0a",
   "metadata": {},
   "source": [
    "12. Let's investigate an alternative method for finding the confusion matrix. You can use the `pd.crosstab()` function--the benefit of this function is that you have more control over what is in the rows and what is in the columns. See if you can use it to find the confusion matrix and accuracy metrics using a threshold of 0.5. How do your metrics compare to the metrics of the training set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d5c42-d365-4c64-b57d-72f72a3ca590",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5171d30-3943-4037-b05f-55898986cb85",
   "metadata": {},
   "source": [
    "13. A final method that might be nice to use in reports and such is the .... method from `sklearn`. See the code below for evaluating the confusion matrix on the training set. Can you adapt the code to return the confusion matrix for the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89675f8-d9c9-423e-b6dd-448aa0036091",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.confusion_matrix(Y_train, model1.predict() > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7656c9af-d458-4f57-8fad-c845259461b9",
   "metadata": {},
   "source": [
    "14. Another helpful function in `sklearn` is the AUC method. See the code below for evaluating the AUC of the training set. Can you adapt the code to return the AUC of the test set? You can read the [AUC documentation](https://www.w3schools.com/python/python_ml_auc_roc.asp) if you need it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e92ad-fc9e-47ed-8ecb-6e6354c47fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_train, model1.predict(), \n",
    "                                         pos_label=1)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f528bc-f073-490c-be15-944fbb0ca92e",
   "metadata": {},
   "source": [
    "## LASSO\n",
    "\n",
    "15. Now let's move onto fitting the LASSO. Before we do anything else, we need to standardize the data. Luckily, `sklearn` has a method for us--`StandardScaler`. We want to apply this method to the training set, while also saving it to use later for the test set. Familiarize yourself with the code below so that you know how to use these functions in the future. In case you need it, you can find [the documentation for `StandardScaler` here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "\n",
    "Note--because we standardize, we do not have to include a constant term! We can re-define `X_train` to exclude that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83538c-a721-49c9-af82-f3f60b59a480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = arrests_train[['year', 'age', 'checks', 'race_Black', 'sex_Male', 'employed_Yes', 'citizen_Yes']]\n",
    "X_test = arrests_test[['year', 'age', 'checks', 'race_Black', 'sex_Male', 'employed_Yes', 'citizen_Yes']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_pp = pd.DataFrame(scaler.transform(X_train), columns = [['year', 'age', 'checks', 'race_Black', 'sex_Male', 'employed_Yes', 'citizen_Yes']])\n",
    "X_test_pp = pd.DataFrame(scaler.transform(X_test), columns = [['year', 'age', 'checks', 'race_Black', 'sex_Male', 'employed_Yes', 'citizen_Yes']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de314a8c-7cd7-481c-b4c5-3c56cd6a2b54",
   "metadata": {},
   "source": [
    "16. Remember that LASSO is also used for feature selection, so it is common to fit a model with all of the variables for a wide range of threshold parameters. The most straightforward way to do this is to use the `linear_model.LogisticRegression` method from `sklearn`. Read the documentation for this function and fit a model predicting whether an individual is arrested from all of the variables (ignore the threshold parameter for now). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4553022-4ce2-4f66-8888-694cd759a9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af5c4edb-c342-43b0-9ffa-bb008e74d7f3",
   "metadata": {},
   "source": [
    "17. Once you read the documentation and successfully fit the model, you should find that it is relatively simple to adapt your code to fit a regularized version (a.k.a., the LASSO). Different software programs have different names for the threshold parameter--read [the documentation for logistic regression in `sklearn`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to find out what it is called for `sklearn`. What values can you input? Adapt the code from 16. to turn this into a LASSO (just to test, use `C = 1.0`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782f555-176e-407a-918a-7c1b368e2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = sklearn.linear_model.LogisticRegression()\n",
    "model3.fit(X_train_pp, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2709cf83-f288-412b-9d40-86b91fd56400",
   "metadata": {},
   "source": [
    "18. Remember that we need to pick the right parameter ($t$ from the lecture notes, `C` in `sklearn`). There are a variety of ways to go about this, but the most straightforward way is to write a loop fitting the model multiple times, saving the following:\n",
    "\n",
    "* The value of the threshold you used to fit the model,\n",
    "* The coefficients of the model,\n",
    "* The AUC (or some other model fit statistic) evaluated on the training set. \n",
    "\n",
    "First, create objects to store the coefficients and the AUC (we'll save the thresholds separately). I found it most helpful to use lists and dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b0b44-4802-40bf-8f38-d167ba0b4a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_lasso = pd.DataFrame()\n",
    "auc_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d211c3-1af5-461e-aa00-86a3640af3ca",
   "metadata": {},
   "source": [
    "19. Next, select a range of \"budget parameters\". In the notes we called this $t$, in `sklearn`, it is called `C`. This will be what you iterate over in your loop and a piece that you will need if you want to graph the coefficients. I mentioned in class that this can take some trial and error--I used the range 0.00001 to 0.2 in increments of 0.001, but in the future you might have to run multiple loops to get something reasonable. \n",
    "\n",
    "To actually create the range, you can use `np.arange()` (must be used instead of `range()` for floats). Save it in `Cs`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7776a6ab-c468-442f-b858-c948219e554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ded7cc-96d7-4c92-ba5d-3376d2222c9b",
   "metadata": {},
   "source": [
    "20. Now, use `Cs` to create the loop. You can use the code from 14. and 17. to write the contents of the loops. Code one instance of the loop below (again, I used `C = 1.0` to test the code), making sure you are properly saving the objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e61ecbe-d839-4410-8f9b-11b53e2ac9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_lasso = pd.DataFrame()\n",
    "auc_list = []\n",
    "  \n",
    "model = \n",
    "tempmodel = \n",
    "pd.concat()\n",
    "pred = tempmodel.predict()\n",
    "fpr, tpr, thresholds = \n",
    "auc_list.append()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682c8041-a441-4e94-a0e7-8c2d67cff66b",
   "metadata": {},
   "source": [
    "21. Now, combine 18., 19., and 20. to write the full loop and run it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda5d83-0141-4748-a76b-9eecccb24e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_lasso = pd.DataFrame()\n",
    "auc_list = []\n",
    "\n",
    "for threshold in Cs:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3855fb1-af7f-4026-9e4e-fa3a636e592f",
   "metadata": {},
   "source": [
    "22. We have learned previously that to create plots with `plotnine` we need to create a dataframe. Create a dataframe with columns for `threshold` and each of the coefficients in the model--you may want to rename the columns for convenience later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f995fa8-ee5a-462e-9c9d-50b15fef3adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "674e4770-c6a3-4335-8dfe-df5af8a90003",
   "metadata": {},
   "source": [
    "# LASSO Plots\n",
    "\n",
    "23. Now let's work on making the plot comparing the coefficients to the threshold. You have used `geom_histogram()` and `geom_point()` before, but let's introduce a new geom, `geom_line()`. This will plot all values and connect them with a line. Fill in the shell code below to create the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b631643-fbe1-42b6-8110-287355fb4e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(arrests_lasso_plt, p9.aes()) +\n",
    "  p9.geom_line())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ba1f3b-7b43-4f88-834a-2fed7dc09e33",
   "metadata": {},
   "source": [
    "24. Hopefully, you have identified that you can only specify one `x` value--but we have multiple coefficients we would like to investigate! We need to make a change to the dataframe so that there are two new columns--one with all the coefficient values, and one giving the variables it belongs to. We can use `pd.melt` to do so--familiarize yourself with the code below so that you know how to use these functions in the future. The column with all the coefficient values is now `Coefficient`, and the column with the variables is `Variable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47434b40-3181-4db5-a2cd-fa6404891500",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrests_lasso_plt_melt = pd.melt(arrests_lasso_plt, id_vars = 'Threshold', \n",
    "                                var_name = 'Variable', value_name = 'Coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3078ab-82be-4d0b-8a02-d26573735ace",
   "metadata": {},
   "source": [
    "25. Now, adapt your `plotnine` code to get multiple lines on the graph using `x = 'Threshold'` and `y = 'Coefficient'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e341712-afce-4736-81f1-dffdb762d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot() +\n",
    "  p9.geom())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f3f232-8e8a-45cb-a46e-ae5b150e64df",
   "metadata": {},
   "source": [
    "26. That does not look right! The line is connecting every single value. To fix this problem and to make it more visually appealing, we can also change the color according to the variable `Variable`. Add the line to the `aes()` statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef127c1-53a9-4f8b-bc17-f276eee03e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc082442-6e03-4fb5-ae5c-e98db65156c0",
   "metadata": {},
   "source": [
    "27. The colors are helpful, but it is more helpful to have labels directly on the graph. This is a bit more complicated. We can use the `geom_text()` geom, but it will label every point--run the code below to confirm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b74b8-fe97-42ca-9037-7c3b32e0b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(arrests_lasso_plt_melt, p9.aes(x = 'Threshold', y = 'Coefficient', \n",
    "                                          color = 'Variable')) +\n",
    "  p9.geom_line() +\n",
    "  p9.geom_label(mapping = p9.aes(label = 'Variable')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41fbddf-b195-49f0-9974-34f82404822d",
   "metadata": {},
   "source": [
    "28. I found that if you only want a few values, it was the most straightforward to create a new dataframe with only those values. Note that in the previous line of code you need an `x` and `y` coordinate--I picked the largest value of the threshold possible for `x` and the the largest coefficient value for each of the variables. You can do this easily with filtering--see the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4331e7-1659-41f8-94a5-3636a2594779",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_T = arrests_lasso_plt_melt['Threshold'].loc[arrests_lasso_plt_melt.shape[0]-1]\n",
    "\n",
    "plt_label = arrests_lasso_plt_melt[(arrests_lasso_plt_melt['Threshold'] == max_T)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b751e78-aa0a-417c-9a30-e605da005dac",
   "metadata": {},
   "source": [
    "29. Now, we can adapt the `geom_text()` code. Note that there is a new argument, `inherit.aes = False`. This is telling `plotnine` that we no longer want the aesthetics from the first line! Once we do this, we also have to resupply the `data` and aesthetics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f99940-e0c2-4615-8eea-65db30187c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(arrests_lasso_plt_melt, p9.aes(x = 'Threshold', y = 'Coefficient', \n",
    "                                          color = 'Variable')) +\n",
    "  p9.geom_line() +\n",
    "  p9.geom_label(inherit_aes = False, data = plt_label, \n",
    "                mapping = p9.aes(label = 'Variable', x = 0.2, \n",
    "                                 y = 'Coefficient', color = 'Variable')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a71a477-77f5-4a3a-aae5-acb3dcbcb016",
   "metadata": {},
   "source": [
    "30. This is very close to what we want, but for the sake of readability, let's take the legend out--we don't need it since the labels are right on the graph. You can also adjust the axes a bit so the full labels don't get cut off. Run the code below--perfect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04978143-6a05-4ce8-be56-7a986c37ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(arrests_lasso_plt_melt, p9.aes(x = 'Threshold', y = 'Coefficient', \n",
    "                                          color = 'Variable')) +\n",
    "  p9.geom_line() +\n",
    "  p9.scale_x_continuous(limits = [0, 0.22]) +\n",
    "  p9.theme(legend_position = \"none\") +\n",
    "  p9.geom_label(inherit_aes = False, data = plt_label, \n",
    "                mapping = p9.aes(label = 'Variable', x = 0.2, \n",
    "                                 y = 'Coefficient', color = 'Variable')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789d6b3-d8bb-4cf4-b78b-e2f4a0e9eaa4",
   "metadata": {},
   "source": [
    "# Threshold Selection\n",
    "\n",
    "31. Last, let's look at the AUC of the test set to pick our actual parameter. Print out some of the values, and identify the max AUC possible. Is it good or bad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943935b0-da3c-4512-b13d-15418a4ef1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d23b8d5-b77d-41bc-9d17-4a195a4bf8ce",
   "metadata": {},
   "source": [
    "\n",
    "32. Locate the threshold that gives you the highest classifier. What terms are included in the model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64997de2-b620-469e-a2df-d7c1a54b9cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5204c7f9-29b8-44c2-81af-e5232b36a8b7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
