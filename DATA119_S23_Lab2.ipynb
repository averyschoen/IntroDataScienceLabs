{
 "cells": [
  {
   "cell_type": "raw",
   "id": "43ee2c71-62e0-4da4-b000-eeb45d5fa687",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"DATA 119 S23 Lab 2 Solutions\"\n",
    "name: \"Amy Nussbaum\"\n",
    "format: pdf\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222423d4-24f8-47f3-ae03-22ecbf9d33a1",
   "metadata": {},
   "source": [
    "# Lab 2 Goals\n",
    "\n",
    "The goals of this lab are:\n",
    "\n",
    "* To continue practicing making data visualizations.\n",
    "* To familiarize yourself with Pearson's correlation coefficient $r$. \n",
    "* To practice writing functions. \n",
    "* To practice calculating linear regression estimates. \n",
    "\n",
    "For this lab, it may be helpful to install and load the following modules: \n",
    "\n",
    "* `plotnine`\n",
    "* `numpy`\n",
    "* `pandas` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37274b-6f6c-4c57-8edf-d383a30304ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine as p9\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6c52f1-a511-4b43-956d-4f7e56b137bf",
   "metadata": {},
   "source": [
    "We will be continuing to use the dataset scraped from the website Epicurious. Let's use the version that we cleaned last week--you can rerun the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e83a7-df84-4855-a376-d9f793bf0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epicurious = pd.read_csv(\"epi_r.csv\")[['title', 'rating', 'calories', 'protein', 'fat', 'sodium']].dropna()\n",
    "\n",
    "maxcal = epicurious['calories'].nlargest(n=10).index\n",
    "maxpro = epicurious['protein'].nlargest(n=10).index\n",
    "maxfat = epicurious['fat'].nlargest(n=10).index\n",
    "maxsod = epicurious['sodium'].nlargest(n=10).index\n",
    "\n",
    "maxvals = set().union(maxcal, maxpro, maxfat, maxsod)\n",
    "\n",
    "epicurious = epicurious.drop(labels = maxvals, axis=0).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232bd585-99b6-4d01-a923-b8d23bc06acb",
   "metadata": {},
   "source": [
    "In addition, we will also be using the following datasets:\n",
    "\n",
    "* `mtcars`\n",
    "* `gasprice`\n",
    "* `eagles`\n",
    "\n",
    "Download the .csv files and load them into your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd6645b-5624-4fe5-bbaa-8d641f4975fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars = pd.read_csv(\"mtcars.csv\")\n",
    "gasprice = pd.read_csv(\"gasprice.csv\")\n",
    "eagles = pd.read_csv(\"eagles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af73af3-67e8-4cf7-bbc0-d3213ecdbe91",
   "metadata": {},
   "source": [
    "## Describing Relationships\n",
    "\n",
    "### `mtcars`\n",
    "\n",
    "The `mtcars` dataset includes [data on fuel consumption and other aspects of 32 cars from a 1974 issue of *Motor Trends* magazine](https://vincentarelbundock.github.io/Rdatasets/doc/datasets/mtcars.html). We are specifically interested in how the weight of the car (`wt`) might impact the car's displacement, which can be thought of as the size of the engine (`disp`).\n",
    "\n",
    "1. Using `plotnine`, create a scatterplot displaying the relationship between weight and displacement. Remember that you should be supplying an `x` and a `y` aesthetic, and that $x$ is traditionally the explanatory variable and $y$ is traditionally the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf6cce3-7145-4cf4-b3a5-7603e31f6bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(p9.aes(x =, y = )) +\n",
    "  p9.geom_point())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f2689-488f-40eb-b508-da5ac949bf0b",
   "metadata": {},
   "source": [
    "Note that `plotnine` has a tool for us to easily add the line of best fit to a plot--it is the function `geom_smooth()`. We need to specify that `geom_smooth` should be using linear regression, which we can do with the argument `method = \"lm\"`.  Recall that you add it directly to the other lines of code. See the example below (note that for the sake of clarity I have added an argument `se = False`, which we will talk about later). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfb170e-2b17-45c9-ac16-8c77cab753da",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(mtcars, p9.aes(x = 'wt', y = 'disp')) +\n",
    "  p9.geom_point() + \n",
    "  p9.geom_smooth(method = \"lm\", se = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7658a0-406f-48aa-80d7-369fd641d24b",
   "metadata": {},
   "source": [
    "2. Describe this relationship in terms of its form, direction, strength, and unusual values. Is a linear relationship appropriate for describing `weight` and `displacement`? If not, what type of relationship might be more appropriate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6790cb81-e06b-4166-ae50-baba3b813a75",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "549d878d-23ec-484b-825e-a72772e7ab56",
   "metadata": {},
   "source": [
    "### `gasprice`\n",
    "\n",
    "The `gasprice` dataset includes data on gas prices in the United States, collected once per week from 1990 to 2003 [documentation here](https://vincentarelbundock.github.io/Rdatasets/doc/quantreg/gasprice.html).\n",
    "\n",
    "3. Create a scatterplot displaying the relationship between time (`time`) and gas price (`value`). Add the line of best fit to help you describe the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f4466-a621-46ae-958d-d4d392ed6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(p9.aes()) +\n",
    "  p9.geom() + \n",
    "  p9.geom_smooth(method = \"lm\", se = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982e6989-59c0-42bc-a8ff-d840946eb0ec",
   "metadata": {},
   "source": [
    "4. Describe this relationship in terms of its form, direction, strength, and unusual values. Is a linear relationship appropriate for describing `time` and `value`? If not, what type of relationship might be more appropriate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ba6e5-ef09-4123-8f58-e8f64945a244",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f579bb0a-8135-4f18-845e-7a40a045b4ee",
   "metadata": {},
   "source": [
    "### `eagles`\n",
    "\n",
    "The `eagles` dataset contains information the number of mating pairs of bald eagles in the United States. In 1967, bald eagles officially became an endangered species, and in 1972, the use of DDT (a pesticide causing damage to the shells of the eagle eggs) was banned--scientists have been tracking the population since (<https://courses.lumenlearning.com/wmopen-concepts-statistics/chapter/exponential-relationships-1-of-6/>).\n",
    "\n",
    "5. Create a scatterplot displaying the relationship between time (`Year`) and the number of mating pairs (`Pairs`). Add the line of best fit to help you describe the plot. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d34256-80c3-46db-aa29-c331501a74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot() +\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8e7a24-2aec-47f8-9c6e-d9d6f6ba2477",
   "metadata": {},
   "source": [
    "6. Describe this relationship in terms of its form, direction, strength, and unusual values. Is a linear relationship appropriate for describing `Year` and `Pair`? If not, what type of relationship might be more appropriate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab30a5-b5af-40d3-848f-2fef06a9a4f8",
   "metadata": {},
   "source": [
    "\\textcolor{blue}{This is once more a strong, positive relationship with maybe one unusual value on the lefthand side, but once again is not linear. It is also a curve--specifically, an example of exponential growth.}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b346c73-e971-4ef1-b59a-ba2eeb2383c8",
   "metadata": {},
   "source": [
    "7. Now confirm the value of the correlation between `Year` and `Pairs`--I used `.corr()`, but you will need to pull the columns of `Year` and `Pair` out of their dataframe. Would you describe this as weak, moderate, or strong based on $r$? Is this consistent with your findings from the graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3404bf2b-b7a3-41ca-a94b-fe169c08e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Year = eagles['Year']\n",
    "Pairs = eagles['Pairs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65773832-988b-41a0-95c9-fb4c3fe1e53e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b557db7-b4c3-4c5e-9f34-407a9d1226aa",
   "metadata": {},
   "source": [
    "As it turns out, the relationship between year and number of mating pairs is best described with an exponential relationship, not a straight line! However, we can see that the correlation is very strong--if we looked at $r$ alone, we might think that this data has a very strong linear relationship. This is why it is important to consider both the plot and the correlation at the same time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000df7e-919c-4e4c-855d-95f06c5a1e72",
   "metadata": {},
   "source": [
    "### `epicurious`\n",
    "\n",
    "8. For the remaining exercises, we will treat `fat` as an explanatory variable and `calories` as the response variable. Create a scatterplot displaying the relationship between `fat` and `calories`. Be sure to put the variables on the appropriate axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a93bc17-5975-4bd9-be0e-f29a244bea1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9552d6c7-fb81-45d1-a076-b529324bd9df",
   "metadata": {},
   "source": [
    "9. Describe this relationship in terms of its form, direction, strength, and unusual values. Is a linear relationship appropriate for describing `fat` and `calories`? If not, what type of relationship might be more appropriate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876510e6-bd84-4b44-bbdc-224c0c91cded",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae3b9d3a-bb5d-4682-8b84-37175325a401",
   "metadata": {},
   "source": [
    "10. Now, define series `fat` and `calories` to calculate the correlation between `fat` and `calories`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2669bb88-faee-44df-bf7b-cf23caa8e54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12debf24-5909-4668-b303-f371cafe87b0",
   "metadata": {},
   "source": [
    "11. It turns out that there are 28.346 grams of fat in an ounce. Create a new list called `fat_oz` containing the amount fat in the recipe in ounces. Now, calculate the correlation between `fat_oz` and `calories`. What is the value of $r$? Is this what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5498b0ed-1b86-4eaa-a6de-2e6f886e6895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88b43e47-ddcf-457b-870c-c7d78f5c1806",
   "metadata": {},
   "source": [
    "The answer should be identical. This is because correlation is *unitless*--it does not depend on the units of either of the variables. \n",
    "\n",
    "12. Now suppose we want to treat `calories` as the explanatory variable and `fat` as the explanatory variable. Calculate the correlation between `calories` and `fat`. Now what is the value of $r$? Is this what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f3ea0-1e09-4acb-9843-7663397944b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6ff68e7-41a8-4c37-9d68-c0428dae054f",
   "metadata": {},
   "source": [
    "If you switch the places, nothing happens! The correlation of the two variables is the same no matter which is treated as the explanatory variable, $X$, and which is treated as the response variable, $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a07e7e-7400-4043-bef3-8987c88d0312",
   "metadata": {},
   "source": [
    "## Writing Functions\n",
    "\n",
    "### Slope\n",
    "\n",
    "Occasionally we want to perform calculations and repeat them over and over again--this is an excellent place to write a function. \n",
    "\n",
    "13. Using the equation \n",
    "\n",
    "$$b_1 = r \\times \\frac{s_y}{s_x},$$\n",
    "\n",
    "write a function called `calc_slope` that will calculate the estimate of the slope, $b_1$, given the correlation between two variables, the standard deviation of the explanatory variable, and the standard deviation of the response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7553f86-2bb7-4f84-bdd4-1c7e15099c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_slope(r_xy, s_x, s_y):\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2bfa17-81a8-423b-9361-c131f3160bcc",
   "metadata": {},
   "source": [
    "14. Now, apply your function to the `epicurious` data--you may want to calculate the summary statistics for the dataset first (save the correlation as `r_fatcal` and the standard deviations as `s_fat` and `s_cal`). When predicting `calories` from `fat`, what is the estimate of the slope? What is the interpretation of the slope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c36e9c-323b-4b21-a664-87aabb4d3a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epicurious.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8ce3c2-8761-4799-a35a-fd673be3a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_slope(r_fatcal, s_fat, s_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f96faad-e8ff-4c41-906f-457f8910a10c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82a69338-d5b8-4f5d-9bb9-478fc2237ab3",
   "metadata": {},
   "source": [
    "### Intercept\n",
    "\n",
    "15. We also need to frequently calculate the intercept. Using the equation \n",
    "\n",
    "$$b_0 = \\bar{y} - b_1\\bar{x}$$\n",
    "\n",
    "Write a function called `calc_int` that will calculate the estimate of the intercept, $b_0$, given the correlation between two variables, the standard deviations of both the explanatory and response variables, and the means of both the explanatory and response variables. Your new function should use the `calc_slope` function you just wrote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0bd2ef-f874-4986-b7ea-7fcb06b42ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_int():\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf8c9f-bc12-4e29-a44d-3d0e0419fb8d",
   "metadata": {},
   "source": [
    "16. Now apply your function to the `epicurious` data (save the means as `m_fat` and `m_cal`). When predicting `calories` from `fat`, what is the estimate of the intercept? What is the interpretation of the intercept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67cfb65-2515-4a20-8379-ab06c7fbf7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c85a5-ab5c-4cf7-8779-d06ab3b4a71a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d774c434-9208-4032-bac3-44c2bde712bf",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "17. One of the linear regression tasks we are usually interested in is prediction. Write a function called `calc_predict` that can predict values of $y$ from $x$ given a column of data for the explanatory variable and a column of data for the response. Your new function should use both the `calc_slope` and `calc_int` functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8015bd-4b28-4ca5-b714-6ec3f611e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(x, y):\n",
    "    r_xy = x.corr(y)\n",
    "        \n",
    "    return(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b51a7d7-a881-432b-acf5-a5f312d9b2e2",
   "metadata": {},
   "source": [
    "18. Now, apply the function to the `epicurious` dataset and save a list of calorie predictions as `pred_cal`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64072d-22de-4793-978c-b981e6b973ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cal = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eed1431-c634-4345-9373-6df5aa0efbd8",
   "metadata": {},
   "source": [
    "### Residuals\n",
    "\n",
    "19. We will definitely need to repeatedly calculate the residuals. Write a function called `calc_res` that can calculate the residuals for the entire dataset, given a column of data for the explanatory variable, and a column of data for the response. Your new function should use at least one of the functions you have already written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60086040-79e9-4320-a2b4-5f95255325ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fdab220-003b-4880-b41d-67dd3d7ad261",
   "metadata": {},
   "source": [
    "20. Now, apply the function to the `epicurious` dataset and save a list of residuals as `res_cal`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf10eee-03fa-44a5-ae79-891ef650ebf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef7e3400-d16a-4d27-a1f1-02d85e3d523a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loss Function\n",
    "\n",
    "21. Hopefully, you remember that the loss function for simple linear regression is the sum of the squared residuals (also known as the sum of squared errors, or SSE). Write a function called `calc_SSE` that returns a single value given a column of data for the explanatory variable, and a column of data for the response. Your function should refer to all of the functions you have previously written. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5617cb11-ae01-4007-aa41-d807d3f56f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_SSE(x, y):  \n",
    "\n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71885682-c7bc-4768-b758-2a0a4c67425b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optimization\n",
    "\n",
    "We are lucky to have equations (more formally known as closed form estimators) to estimate the slope and the intercept. However, this is not always the case! Recall that the estimates are derived from minimizing the sum of the squared residuals--when we don't have closed form estimators (which happens frequently in more complicated models), we will have to use computers to minimize our loss function. Then, the estimates we are looking for are the values where the loss function is minimized.\n",
    "\n",
    "Minimizing a loss function is a special case of *optimization*. To optimize, we will need the `scipy` module--install and load it now. From `scipy.optimize`, we specifically need `minimize`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9486b0aa-dac1-438d-bbb9-61c066dad4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae906bc7-e965-42b4-86f0-ede6338feb4e",
   "metadata": {},
   "source": [
    "The `minimize` method accepts many different arguments, but here's what we are specifically concerned about:\n",
    "\n",
    "* `fun`, the objective function to be minimized.\n",
    "* `x0`, an initial guess for the values we are looking for. \n",
    "\n",
    "You can read more about the other arguments, which may come into play with more complicated models, in the [scipy.optimize.minimize documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html). You will have to specify a method, for most problems, `method=\"BFGS\"` will work.\n",
    "\n",
    "In this case, the objective function is the loss function we happen to be using--in the case of linear regression, the SSE function. We can't just use the function as is, it has to have a special format. \n",
    "\n",
    "* The first argument needs contain the values that you are looking for, in this case, the slope and intercept. Other things you need can go next. \n",
    "* The function must return the loss function, in this case, the SSE. \n",
    "\n",
    "22. Adapt your `calc_SSE` function so that it follows these requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cdf67b-21f4-4792-9261-268a201db400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_SSE(parms, x, y):  \n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1f299-a80c-4f14-9f22-5cb484986187",
   "metadata": {},
   "source": [
    "We can give any real values for the initial guesses, but we have to give at least two, one for the intercept and one for the slope. For now, we can just use zero for both--create an array, `init`, containing two zeroes to use as initial values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec878587-dcbd-45d4-84b1-11a7c18f2266",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = [0]*2\n",
    "init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543e77a0-ef2d-4a7b-bcfc-7595c9412889",
   "metadata": {},
   "source": [
    "Now, we can use these pieces with `minimize()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4b267-a039-47d4-a461-0956f95b1245",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(calc_SSE, x0 = init, args = (fat, calories), method = \"BFGS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842a73d-843f-4ad1-8f6d-cc4a70ac7df5",
   "metadata": {},
   "source": [
    "23. Confirm that these answers are the same as the estimates you calculated with the equations from lecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250df532-f58d-4963-a41f-ef6ecd1c6960",
   "metadata": {},
   "source": [
    "## `statsmodels`\n",
    "\n",
    "In addition to writing your own functions, either to directly estimate parameters or to minimize the loss function, there are a lot of pre-packaged methods in Python to use for linear regression. You may be familiar with `scikit-learn` already, but I want to introduce another module, `statsmodels`. Both modules work similarly, but `statsmodels` has some functionality that will help us out in future weeks. \n",
    "\n",
    "24. Install the `statsmodels` module, and load `statsmodels.api`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b54c620-af9f-40d7-b5f3-f12a31e9acda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30e8e65c-de20-4036-902c-720a5a518f99",
   "metadata": {},
   "source": [
    "To fit a linear regression model with `statsmodels`, we first have to separately save our $X$ and $Y$ variables. Technically, we've already done that with `fat` and `calories`, but review the code below--it's good practice to get into this type of syntax. I've used `X1` since this is our first model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c8bd9-d4cb-48ed-a54e-3b12034c943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = epicurious[\"fat\"]\n",
    "Y = epicurious[\"calories\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770f44bc-8197-4e9d-bf97-47cfb8e0468f",
   "metadata": {},
   "source": [
    "Note that we've only saved one explanatory variable here, but you could save more than one to use with multiple linear regression. \n",
    "\n",
    "By saving `\"fat\"` inside `X1`, we're letting Python know that we want a slope for fat, but we also need to specify that we would like an intercept as well. We do that by using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956155c-140d-4b56-841d-2e3c8dee5883",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = sm.add_constant(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dcc1dc-9134-4ff1-b8c3-76b5eda2075b",
   "metadata": {},
   "source": [
    "Now, we can actually fit the model. We do this with the following line of code (again, I've saved an object called `model1` since this is the first model we are fitting. Also, the only model for this lab, but it's good practice to get into the habit of giving different models different names so you don't write over anything and lose track of what you were doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a8a778-acdf-4653-87db-2053aadd025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = sm.OLS(Y, X1).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb45b0a-d2e4-4465-8801-00b79f8905a0",
   "metadata": {},
   "source": [
    "`statsmodels` knows that people using linear regression are generally going to be performing similar calculations, so there is a lot packed into `model1`. \n",
    "\n",
    "25. Apply the `dir()` function to `model1`, and see if you can identify any of the parts packed into the object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8e8cf-63f6-49f4-8c45-7bea468ea8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "face62bd-4bff-4cfd-86f0-e793f268f843",
   "metadata": {},
   "source": [
    "26. As I mentioned, there is a lot! For now, we just want to use the `.summary()` method. Investigate the output below to see if you can locate where in the table the slope and intercept are located. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b4a8e-88a7-4ecc-a74a-342a3dfcd97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ccac1-baef-435a-8ffc-f17739066494",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
